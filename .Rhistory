df_1$text <- iconv(df_1$lemma, "UTF-8", sub="")
View(df_1)
df_1$text <- iconv(df_1$lemma, "UTF-8", "latin1")
View(df_1)
df_1$text <- iconv(df_1$lemma, "latin1", sub = "")
View(df_1)
df_1 <- data.frame(doc_id = df$status_id, text = df$text, stringsAsFactors = FALSE)
df_1$text <- tolower(df_1$text)
df_1$text <- iconv(df_1$text, "UTF-8", sub="")
View(df_1)
udpipe_annotate(udmodel_spanish, x = iconv(df_1$text, to = 'UTF-8'))
View(udpipe_annotate(udmodel_spanish, x = iconv(df_1$text, to = 'UTF-8')))
udpipe_annotate(udmodel_spanish, x = iconv(df_1$text, to = "UTF-8"))[["x"]]
x <- udpipe_annotate(udmodel_spanish, x = iconv(df_1$text, to = 'UTF-8'))
x <- as.data.frame(x)
View(x)
df <- basic_tweets
df <- df[df$lang == "es", ]
df_1 <- data.frame(doc_id = df$status_id, text = df$text, stringsAsFactors = FALSE)
df_1$text <- tolower(df_1$text)
df_1$text <- iconv(df_1$text, "UTF-8", sub="")
df_1$text <- gsub("@\\w*", "", df_1$text)
df_1$text <- gsub("#\\w*", "", df_1$text)
df_1$text <- gsub("https://t.co/\\w*", "",  df_1$text)
df_1$text <- gsub("[[:punct:]]", "", df_1$text)
df_1$text <- gsub("\\\\s", "",df_1$text)
ud_model <- udpipe_download_model(language = "spanish")
ud_model <- udpipe_load_model(ud_model$file_model)
x <- udpipe_annotate(ud_model, x = iconv(df_1$text, to = 'UTF-8'))
df_1 <- as.data.frame(x)
df_1 <- df_1 %>%
select(doc_id, lemma, upos)
stop_words <- c(stopwords::stopwords("es", source = "stopwords-iso"),stopwords::stopwords(source = "smart"))
df_1 <- df_1[!(df_1$lemma %in% stop_words),]
df_1 <- df_1[complete.cases(df_1),]
df_1 <- df_1[df_1$upos != "SYM" & df_1$upos !="PUNCT",]
df_1$text <- iconv(df_1$lemma, "UTF-8", sub="")
text <- list()
for(i in 1:length(unique(df_1$doc_id))){
text[[i]] <-  paste0(df_1[df_1$doc_id == unique(df_1$doc_id)[i],]$lemma, collapse=" ")
}
df$text <- unlist(text)
View(df$text)
View(df)
View(basic_tweets)
preprocess <- function(df, ud_lang, stopwords_lang){
tmp <- data.frame(doc_id = df$status_id, text = df$text, stringsAsFactors = FALSE)
tmp$text <- tolower(tmp$text)
tmp$text <- iconv(tmp$text, "UTF-8", sub="")
tmp$text <- gsub("@\\w*", "", tmp$text)
tmp$text <- gsub("#\\w*", "", tmp$text)
tmp$text <- gsub("https://t.co/\\w*", "",  tmp$text)
tmp$text <- gsub("[[:punct:]]", "", tmp$text)
tmp$text <- gsub("\\\\s", "",tmp$text)
ud_model <- udpipe_download_model(language = ud_lang)
ud_model <- udpipe_load_model(ud_model$file_model)
x <- udpipe_annotate(ud_model, x = iconv(tmp$text, to = 'UTF-8'))
tmp <- as.data.frame(x)
tmp <- tmp %>%
select(doc_id, lemma, upos)
stop_words <- c(stopwords::stopwords(stopwords_lang, source = "stopwords-iso"),stopwords::stopwords(source = "smart"))
tmp <- tmp[!(tmp$lemma %in% stop_words),]
tmp <- tmp[complete.cases(tmp),]
tmp <- tmp[tmp$upos != "SYM" & tmp$upos !="PUNCT",]
tmp$text <- iconv(tmp$lemma, "UTF-8", sub="")
text <- list()
for(i in 1:length(unique(tmp$doc_id))){
text[[i]] <-  paste0(tmp[tmp$doc_id == unique(tmp$doc_id)[i],]$lemma, collapse=" ")
}
tmp.2 <- df
tmp.2$text <- unlist(text)
return(tmp.2)
}
d <- preprocess(basic_tweets, ud_lang = "spanish", stopwords_lang = "es")
df <- basic_tweets
tmp <- data.frame(doc_id = df$status_id, text = df$text, stringsAsFactors = FALSE)
tmp$text <- tolower(tmp$text)
tmp$text <- iconv(tmp$text, "UTF-8", sub="")
tmp$text <- gsub("@\\w*", "", tmp$text)
tmp$text <- gsub("#\\w*", "", tmp$text)
tmp$text <- gsub("https://t.co/\\w*", "",  tmp$text)
tmp$text <- gsub("[[:punct:]]", "", tmp$text)
tmp$text <- gsub("\\\\s", "",tmp$text)
ud_model <- udpipe_load_model(ud_model$file_model)
x <- udpipe_annotate(ud_model, x = iconv(tmp$text, to = 'UTF-8'))
tmp <- as.data.frame(x)
tmp <- tmp %>%
select(doc_id, lemma, upos)
stop_words <- c(stopwords::stopwords(stopwords_lang, source = "stopwords-iso"),stopwords::stopwords(source = "smart"))
tmp <- tmp[!(tmp$lemma %in% stop_words),]
tmp <- tmp[complete.cases(tmp),]
tmp <- tmp[tmp$upos != "SYM" & tmp$upos !="PUNCT",]
tmp$text <- iconv(tmp$lemma, "UTF-8", sub="")
text <- list()
for(i in 1:length(unique(tmp$doc_id))){
text[[i]] <-  paste0(tmp[tmp$doc_id == unique(tmp$doc_id)[i],]$lemma, collapse=" ")
}
tmp.2 <- df
View(tmp.2)
tmp.2$text <- unlist(text)
View(text)
tmp$text <- unlist(text)
View(tmp)
View(tmp)
View(tmp)
tmp <- data.frame(doc_id = df$status_id, text = df$text, stringsAsFactors = FALSE)
View(tmp)
tmp$text <- tolower(tmp$text)
tmp$text <- iconv(tmp$text, "UTF-8", sub="")
tmp$text <- gsub("@\\w*", "", tmp$text)
tmp$text <- gsub("#\\w*", "", tmp$text)
tmp$text <- gsub("https://t.co/\\w*", "",  tmp$text)
tmp$text <- gsub("[[:punct:]]", "", tmp$text)
tmp$text <- gsub("\\\\s", "",tmp$text)
x <- udpipe_annotate(ud_model, x = iconv(tmp$text, to = 'UTF-8'))
tmp_1 <- as.data.frame(x)
View(tmp_1)
tmp <- data.frame(doc_id = df$status_id, text = df$text, stringsAsFactors = FALSE)
tmp$text <- tolower(tmp$text)
tmp$text <- iconv(tmp$text, "UTF-8", sub="")
tmp$text <- gsub("@\\w*", "", tmp$text)
tmp$text <- gsub("#\\w*", "", tmp$text)
tmp$text <- gsub("https://t.co/\\w*", "",  tmp$text)
tmp$text <- gsub("[[:punct:]]", "", tmp$text)
tmp$text <- gsub("\\\\s", "",tmp$text)
x <- udpipe_annotate(ud_model, x = iconv(tmp$text, to = 'UTF-8'))
tmp_1 <- as.data.frame(x)
tmp_1 <- tmp_1 %>%
select(doc_id, lemma, upos)
stop_words <- c(stopwords::stopwords(stopwords_lang, source = "stopwords-iso"),stopwords::stopwords(source = "smart"))
tmp_1 <- tmp_1[!(tmp_1$lemma %in% stop_words),]
tmp_1 <- tmp_1[complete.cases(tmp_1),]
tmp_1 <- tmp_1[tmp_1$upos != "SYM" & tmp_1$upos !="PUNCT",]
View(tmp_1)
text <- list()
for(i in 1:length(unique(tmp_1$doc_id))){
text[[i]] <-  paste0(tmp_1[tmp_1$doc_id == unique(tmp_1$doc_id)[i],]$lemma, collapse=" ")
}
text <- unlist(text)
tmp$text <- text
View(tmp_1)
text <- list()
for(i in 1:length(unique(tmp_1$doc_id))){
text <-  paste0(tmp_1[tmp_1$doc_id == unique(tmp_1$doc_id)[i],]$lemma, collapse=" ")
doc <- unique(tmp_1$doc_id)[i]
text[[i]] <- c(doc, text)
}
preprocess <- list()
for(i in 1:length(unique(tmp_1$doc_id))){
text <-  paste0(tmp_1[tmp_1$doc_id == unique(tmp_1$doc_id)[i],]$lemma, collapse=" ")
doc <- unique(tmp_1$doc_id)[i]
preprocess[[i]] <- c(doc, text)
}
preprocess[[1]]
preprocess_tmp <- do.call(rbind, preprocess)
Voew(preprocess_tmp)
View(preprocess_tmp)
View(tmp)
View(tmp_1)
udpipe(x = iconv(tmp$text, to = 'UTF-8') object = "spanish", trace = 10)
udpipe(x = iconv(tmp$text, to = 'UTF-8'), object = "spanish", trace = 10)
tmp_2 <- udpipe(x = iconv(tmp$text, to = 'UTF-8'), object = "spanish", trace = 10)
View(tmp_2)
tmp$text <- iconv(tmp$text, to = 'UTF-8')
tmp_2 <- udpipe(x = tmp, object = "spanish", trace = 10)
View(tmp_2)
df <- basic_tweets
tmp <- data.frame(doc_id = df$status_id, text = df$text, stringsAsFactors = FALSE)
tmp$text <- tolower(tmp$text)
tmp$text <- iconv(tmp$text, "UTF-8", sub="")
tmp$text <- gsub("@\\w*", "", tmp$text)
tmp$text <- gsub("#\\w*", "", tmp$text)
tmp$text <- gsub("https://t.co/\\w*", "",  tmp$text)
tmp$text <- gsub("[[:punct:]]", "", tmp$text)
tmp$text <- gsub("\\\\s", "",tmp$text)
tmp$text <- iconv(tmp$text, to = 'UTF-8')
tmp_1 <- udpipe(x = tmp, object = "spanish", trace = 10)
tmp_1 <- tmp_1 %>%
select(doc_id, lemma, upos)
tmp_1 <- tmp_1[!(tmp_1$lemma %in% stop_words),]
tmp_1 <- tmp_1[complete.cases(tmp_1),]
tmp_1 <- tmp_1[tmp_1$upos != "SYM" & tmp_1$upos !="PUNCT",]
View(tmp_1)
preprocess <- list()
for(i in 1:length(unique(tmp_1$doc_id))){
text <-  paste0(tmp_1[tmp_1$doc_id == unique(tmp_1$doc_id)[i],]$lemma, collapse=" ")
doc <- unique(tmp_1$doc_id)[i]
preprocess[[i]] <- c(doc, text)
}
preprocess_tmp <- do.call(rbind, preprocess)
View(preprocess_tmp)
View(tmp)
preprocess_tmp <- as.data.frame(preprocess_tmp)
df_1 <- df[df$status_id %in% preprocess_tmp$V1, ]
View(df_1)
tt <- c(df_1$status_id, preprocess_tmp$V1)
View(tt)
tt <- cbind(df_1$status_id, preprocess_tmp$V1)
View(tt)
preprocess <- function(df, ud_lang, stopwords_lang){
tmp <- data.frame(doc_id = df$status_id, text = df$text, stringsAsFactors = FALSE)
tmp$text <- tolower(tmp$text)
tmp$text <- iconv(tmp$text, "UTF-8", sub="")
tmp$text <- gsub("@\\w*", "", tmp$text)
tmp$text <- gsub("#\\w*", "", tmp$text)
tmp$text <- gsub("https://t.co/\\w*", "",  tmp$text)
tmp$text <- gsub("[[:punct:]]", "", tmp$text)
tmp$text <- gsub("\\\\s", "",tmp$text)
tmp$text <- iconv(tmp$text, to = 'UTF-8')
tmp_1 <- udpipe(x = tmp, object = "spanish", trace = 10)
tmp_1 <- tmp_1 %>%
select(doc_id, lemma, upos)
stop_words <- c(stopwords::stopwords(stopwords_lang, source = "stopwords-iso"),stopwords::stopwords(source = "smart"))
tmp_1 <- tmp_1[!(tmp_1$lemma %in% stop_words),]
tmp_1 <- tmp_1[complete.cases(tmp_1),]
tmp_1 <- tmp_1[tmp_1$upos != "SYM" & tmp_1$upos !="PUNCT",]
preprocess <- list()
for(i in 1:length(unique(tmp_1$doc_id))){
text <-  paste0(tmp_1[tmp_1$doc_id == unique(tmp_1$doc_id)[i],]$lemma, collapse=" ")
doc <- unique(tmp_1$doc_id)[i]
preprocess[[i]] <- c(doc, text)
}
preprocess_tmp <- as.data.frame(do.call(rbind, preprocess))
tmp.2 <- df[df$status_id %in% preprocess_tmp$V1, ]
tmp.2$text <- preprocess_tmp$V2
return(tmp.2)
}
d <- preprocess(basic_tweets, "spanish", "es")
View(d)
library(ComTxt)
topics <- get_topic(d, language = "es", n_topic = 7)
library(mallet)
library(stopwords)
topics <- get_topic(d, language = "es", n_topic = 7)
View(d)
library(dplyr) #Data manipulation (also included in the tidyverse package)
library(tidytext) #Text mining
library(tidyr) #Spread, separate, unite, text mining (also included in the tidyverse package)
library(widyr) #Use for pairwise correlation
library(textdata)
library(readxl)
sent_df <- twitter_sentiment(d, language = "es", c("shit"))
NRC_Emotion_Lexicon <- read_excel("source/NRC-Emotion-Lexicon-v0.92-In105Languages-Nov2017Translations.xlsx")
names <- colnames(NRC_Emotion_Lexicon)
names <-gsub(".* ","",names)
names <-gsub("[()]","",name)
twitter_sentiment <- function(df, language, undesirable_words){
stopwords <- data.frame(word = stopwords::stopwords(language, source = "stopwords-iso"))
stopwords$lexicon <- language
stopwords <- as_tibble(stopwords)
NRC_Emotion_Lexicon <- read_excel("source/NRC-Emotion-Lexicon-v0.92-In105Languages-Nov2017Translations.xlsx")
names <- colnames(NRC_Emotion_Lexicon)
names <-gsub(".* ","",names)
names <-gsub("[()]","",names)
colnames(NRC_Emotion_Lexicon) <- names
NRC_Emotion_Lexicon <- NRC_Emotion_Lexicon %>% select(-"en...1")
custom_lexicon <- NRC_Emotion_Lexicon %>% select(language, Anger, Anticipation, Disgust,Fear, Joy, Sadness, Surprise, Trust)
colnames(custom_lexicon) <- c("word", "Anger", "Anticipation", "Disgust","Fear", "Joy", "Sadness", "Surprise", "Trust" )
custom_lexicon <- custom_lexicon[rowSums(custom_lexicon[,2:9]) >0,]
#Create tidy text format: Unnested, Unsummarized, -Undesirables, Stop and Short words
nrc_tidy <- df %>%
unnest_tokens(word, text) %>% #Break the lyrics into individual words
filter(!word %in% undesirable_words) %>% #Remove undesirables
filter(!nchar(word) < 3) %>% #Words like "ah" or "oo" used in music
anti_join(stopwords)
youtube_nrc <- nrc_tidy %>%
inner_join(custom_lexicon)
}
sent_df <- twitter_sentiment(d, language = "es", c("shit"))
twitter_sentiment <- function(df, language, undesirable_words){
#stopwords <- data.frame(word = stopwords::stopwords(language, source = "stopwords-iso"))
#stopwords$lexicon <- language
#stopwords <- as_tibble(stopwords)
NRC_Emotion_Lexicon <- read_excel("source/NRC-Emotion-Lexicon-v0.92-In105Languages-Nov2017Translations.xlsx")
names <- colnames(NRC_Emotion_Lexicon)
names <-gsub(".* ","",names)
names <-gsub("[()]","",names)
colnames(NRC_Emotion_Lexicon) <- names
NRC_Emotion_Lexicon <- NRC_Emotion_Lexicon %>% select(-"en...1")
custom_lexicon <- NRC_Emotion_Lexicon %>% select(language, Anger, Anticipation, Disgust,Fear, Joy, Sadness, Surprise, Trust)
colnames(custom_lexicon) <- c("word", "Anger", "Anticipation", "Disgust","Fear", "Joy", "Sadness", "Surprise", "Trust" )
custom_lexicon <- custom_lexicon[rowSums(custom_lexicon[,2:9]) >0,]
#Create tidy text format: Unnested, Unsummarized, -Undesirables, Stop and Short words
nrc_tidy <- df %>%
unnest_tokens(word, text) %>% #Break the lyrics into individual words
filter(!word %in% undesirable_words) %>% #Remove undesirables
filter(!nchar(word) < 3)
youtube_nrc <- nrc_tidy %>%
inner_join(custom_lexicon)
}
sent_df <- twitter_sentiment(d, language = "es", c("shit"))
bar_sentiment(sent_df)
library(dplyr) #Data manipulation (also included in the tidyverse package)
library(tidytext) #Text mining
library(tidyr) #Spread, separate, unite, text mining (also included in the tidyverse package)
library(widyr) #Use for pairwise correlation
library(textdata)
#Visualizations!
library(ggplot2) #Visualizations (also included in the tidyverse package)
library(ggrepel) #`geom_label_repel`
library(gridExtra) #`grid.arrange()` for multi-graphs
library(knitr) #Create nicely formatted output tables
library(kableExtra) #Create nicely formatted output tables
library(formattable) #For the color_tile function
library(circlize) #Visualizations - chord diagram
library(memery) #Memes - images with plots
library(magick) #Memes - images with plots (image_read)
library(yarrr)  #Pirate plot
library(radarchart) #Visualizations
library(igraph) #ngram network diagrams
library(ggraph)
bar_sentiment(sent_df)
bar_sentiment(sent_df)
words_sentiment(sent_df)
View(sent_df)
youtube_nrc <- d %>%
inner_join("nrc")
youtube_nrc <- d %>%
inner_join(NRC_Emotion_Lexicon)
sent_df[[1]]
sent_df[1]
sent_df[,1]
sent_df[1,1]
sent_df[1,]
View(sent_df[1,])
sent_df[1,]$Anger > 0
sent_df[1,]$Anger
sent_df[1,]$Anger == 1
sent_df[1,]$Joy == 1
sent_df[3,]$Anger == 1
d %>% inner_join(get_sentiments("nrc"))
View(d)
i = 1
if(sent_df[,i]$Anger == 1){
sent_df[,1]$sentiment <- "Anger"
}
sent_df[,i]$Anger
sent_dfÂ«,1$Anger
sent_df[,1]$Anger
class(sent_df[,1])
sent_df[c(1:90, Anger),]
sent_df[1:91,]
View(sent_df[1:91,])
View(sent_df[,1:91])
Anger_df <- sent_df[,1:91]
dd <- Anger_df[Anger_df$Anger == 1,]
View(dd)
Anger_df$Anger <- "Anger"
colnames(Anger_df)[colnames(Anger_df) == "Anger"] <- "sentiment"
View(Anger_df)
df_2 <- sent_df[,c(1:90, 92)]
View(df_2)
df_2<- df_2[92 == 1,]
View(df_2)
df_2<- df_2[,92 == 1]
View(df_2)
df_2<- df_2[,92]
df_2<- df_2[92,]
df_2<- df_2[92]
df_2 <- sent_df[,c(1:90, 92)]
df_3 <- sent_df[,c(1:90, 93)]
df <- rbind(df_1, df_2, df_3)
df <- rbind(df_1, df_2)
df_1 <- sent_df[,1:91]
df_1<- df_1[df_1$Anger == 1,]
df_1$Anger <- "Anger"
colnames(df_1)[colnames(df_1) == "Anger"] <- "sentiment"
df_2 <- sent_df[,c(1:90, 92)]
df_2<- df_2[df_2$Anticipation == 1,]
df_2$Anticipation <- "Anticipation"
colnames(df_2)[colnames(df_2) == "Anticipation"] <- "sentiment"
rbind(df_1, df_2)
dd <- rbind(df_1, df_2)
View(dd)
df_1 <- sent_df[,1:91]
df_1<- df_1[df_1$Anger == 1,]
df_1$Anger <- "Anger"
colnames(df_1)[colnames(df_1) == "Anger"] <- "sentiment"
df_2 <- sent_df[,c(1:90, 92)]
df_2<- df_2[df_2$Anticipation == 1,]
df_2$Anticipation <- "Anticipation"
colnames(df_2)[colnames(df_2) == "Anticipation"] <- "sentiment"
dd <- rbind(df_1, df_2)
View(dd)
View(df_1)
df_1 <- sent_df[,1:91]
View(df_1)
df_1<- df_1[df_1$Anger == 1,]
View(df_1)
View(sent_df)
df_1 <- sent_df[,1:91]
df_1<- df_1[df_1$Anger == 1,]
df_1$Anger <- "Anger"
colnames(df_1)[colnames(df_1) == "Anger"] <- "sentiment"
df_2 <- sent_df[,c(1:90, 92)]
df_2<- df_2[df_2$Anticipation == 1,]
df_2$Anticipation <- "Anticipation"
colnames(df_2)[colnames(df_2) == "Anticipation"] <- "sentiment"
View(df_2)
View(df_1)
df_3 <- sent_df[,c(1:90, 93)]
df_3<- df_2[df_3$Disgust == 1,]
df_3<- df_3[df_3$Disgust == 1,]
df_3$Disgust <- "Disgust"
colnames(df_3)[colnames(df_3) == "Disgust"] <- "sentiment"
df_4 <- sent_df[,c(1:90, 94)]
df_5 <- sent_df[,c(1:90, 95)]
df_6 <- sent_df[,c(1:90, 96)]
df_1 <- sent_df[,1:91]
df_1<- df_1[df_1$Anger == 1,]
df_1$Anger <- "Anger"
colnames(df_1)[colnames(df_1) == "Anger"] <- "sentiment"
df_2 <- sent_df[,c(1:90, 92)]
df_2<- df_2[df_2$Anticipation == 1,]
df_2$Anticipation <- "Anticipation"
colnames(df_2)[colnames(df_2) == "Anticipation"] <- "sentiment"
df_3 <- sent_df[,c(1:90, 93)]
df_3<- df_3[df_3$Disgust == 1,]
df_3$Disgust <- "Disgust"
colnames(df_3)[colnames(df_3) == "Disgust"] <- "sentiment"
df_4 <- sent_df[,c(1:90, 94)]
df_4<- df_4[df_4$Fear == 1,]
df_4$Fear <- "Fear"
colnames(df_4)[colnames(df_4) == "Fear"] <- "sentiment"
df_5 <- sent_df[,c(1:90, 95)]
df_5<- df_5[df_5$Joy == 1,]
df_5$Joy <- "Joy"
colnames(df_5)[colnames(df_5) == "Joy"] <- "sentiment"
df_6 <- sent_df[,c(1:90, 96)]
df_6<- df_6[df_6$Sadness == 1,]
df_6$Sadness <- "Sadness"
colnames(df_6)[colnames(df_6) == "Sadness"] <- "sentiment"
tmp <- rbind(df_1, df_2, df_3, df_4, df_5, df_6)
View(tmp)
tmp_1 <- tmp[c("status_id"),]
tmp_1 <- tmp[,c("status_id")]
View(tmp_1)
tmp_1 <- tmp[,c("status_id", "words", "sentiment")]
tmp_1 <- tmp[,c("status_id", "word", "sentiment")]
View(tmp_1)
df_7 <- sent_df[,c(1:90, 97)]
df_8 <- sent_df[,c(1:90, 98)]
df_7 <- sent_df[,c(1:90, 97)]
df_7<- df_7[df_7$Surprise == 1,]
df_7$Surprises <- "Surprise"
colnames(df_7)[colnames(df_7) == "Surprise"] <- "sentiment"
df_8 <- sent_df[,c(1:90, 98)]
df_8<- df_8[df_8$Trust == 1,]
df_8$Trust <- "Trust"
colnames(df_8)[colnames(df_8) == "Trust"] <- "sentiment"
tmp <- rbind(df_1, df_2, df_3, df_4, df_5, df_6, df_7, df_8)
df_1 <- sent_df[,1:91]
df_1<- df_1[df_1$Anger == 1,]
df_1$Anger <- "Anger"
colnames(df_1)[colnames(df_1) == "Anger"] <- "sentiment"
df_2 <- sent_df[,c(1:90, 92)]
df_2<- df_2[df_2$Anticipation == 1,]
df_2$Anticipation <- "Anticipation"
colnames(df_2)[colnames(df_2) == "Anticipation"] <- "sentiment"
df_3 <- sent_df[,c(1:90, 93)]
df_3<- df_3[df_3$Disgust == 1,]
df_3$Disgust <- "Disgust"
colnames(df_3)[colnames(df_3) == "Disgust"] <- "sentiment"
df_4 <- sent_df[,c(1:90, 94)]
df_4<- df_4[df_4$Fear == 1,]
df_4$Fear <- "Fear"
colnames(df_4)[colnames(df_4) == "Fear"] <- "sentiment"
df_5 <- sent_df[,c(1:90, 95)]
df_5<- df_5[df_5$Joy == 1,]
df_5$Joy <- "Joy"
colnames(df_5)[colnames(df_5) == "Joy"] <- "sentiment"
df_6 <- sent_df[,c(1:90, 96)]
df_6<- df_6[df_6$Sadness == 1,]
df_6$Sadness <- "Sadness"
colnames(df_6)[colnames(df_6) == "Sadness"] <- "sentiment"
df_7 <- sent_df[,c(1:90, 97)]
df_7<- df_7[df_7$Surprise == 1,]
df_7$Surprises <- "Surprise"
colnames(df_7)[colnames(df_7) == "Surprise"] <- "sentiment"
df_8 <- sent_df[,c(1:90, 98)]
df_8<- df_8[df_8$Trust == 1,]
df_8$Trust <- "Trust"
colnames(df_8)[colnames(df_8) == "Trust"] <- "sentiment"
tmp <- rbind(df_1, df_2, df_3, df_4, df_5, df_6, df_7, df_8)
View(df_8)
View(df_7)
df_7 <- sent_df[,c(1:90, 97)]
df_7<- df_7[df_7$Surprise == 1,]
df_7$Surprises <- "Surprise"
colnames(df_7)[colnames(df_7) == "Surprise"] <- "sentiment"
View(df_7)
df_7 <- sent_df[,c(1:90, 97)]
View(df_7)
df_7<- df_7[df_7$Surprise == 1,]
df_7$Surprises <- "Surprise"
View(df_7)
df_7 <- sent_df[,c(1:90, 97)]
df_7<- df_7[df_7$Surprise == 1,]
df_7$Surprise <- "Surprise"
colnames(df_7)[colnames(df_7) == "Surprise"] <- "sentiment"
df_8 <- sent_df[,c(1:90, 98)]
df_8<- df_8[df_8$Trust == 1,]
df_8$Trust <- "Trust"
colnames(df_8)[colnames(df_8) == "Trust"] <- "sentiment"
tmp <- rbind(df_1, df_2, df_3, df_4, df_5, df_6, df_7, df_8)
View(tmp)
tmp[order(tmp$created_at),]
dd <- tmp[order(tmp$created_at),]
View(dd)
words_sentiment(dd)
stopwords::stopwords_getlanguages(source = "stopwords-iso")
library(ComTxt)
