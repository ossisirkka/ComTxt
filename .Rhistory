tmp_df$prob <- unlist(tt)
tmp_df$created_at <- format(as.Date(tmp_df$created_at), "%Y")
tmp_df <- df[rep(seq_len(nrow(df)), each = k), ]
tmp_df$topic <- paste("Topic", rep(1:k,  nrow(df)))
tt <- list()
for(i in 1:nrow(doc.topics.m)){
tt[[i]] <- doc.topics.m[i,]
}
tmp_df$prob <- unlist(tt)
tmp_df$created_at <- format(as.Date(tmp_df$created_at), "%Y")
tt <- list()
for(i in 1:nrow(doc.topics.m)){
tt[[i]] <- doc.topics.m[i,]
}
tmp_df$prob <- unlist(tt)
df <- df_2
tmp_df <- df[rep(seq_len(nrow(df)), each = k), ]
tmp_df$topic <- paste("Topic", rep(1:k,  nrow(df)))
tt <- list()
for(i in 1:nrow(doc.topics.m)){
tt[[i]] <- doc.topics.m[i,]
}
tmp_df$prob <- unlist(tt)
tmp_df$created_at <- format(as.Date(tmp_df$created_at), "%Y")
year_topic <- tmp_df  %>%
group_by(created_at, topic) %>%
count(created_at, topic) %>%
dcast(created_at ~ topic, value.var="prob", fun.aggregate = sum)
setDT(tmp_df)
year_topic <- tmp_df  %>%
group_by(created_at, topic) %>%
count(created_at, topic) %>%
mutate(suffix = str_extract(created_at, "\\d+"))
View(year_topic)
year_topic <- tmp_df  %>%
group_by(created_at, topic) %>%
count(created_at, topic) %>%
mutate(suffix = str_extract(created_at, "\\d+")) %>%
dcast(created_at ~ suffix, value.var="prob", fun.aggregate = sum)
year_topic <- tmp_df  %>%
group_by(created_at, topic) %>%
count(created_at, topic) %>%
mutate(suffix = str_extract(created_at, "\\d+")) %>%
dcast(topic ~ suffix, value.var="prob", fun.aggregate = sum)
year_topic <- tmp_df  %>%
group_by(created_at, topic) %>%
count(created_at, topic) %>%
mutate(suffix = str_extract(created_at, "\\d+")) %>%
dcast(topic ~ suffix, value.var=prob, fun.aggregate = sum)
year_topic <- tmp_df  %>%
group_by(created_at, topic) %>%
count(created_at, topic) %>%
dcast(topic ~ created_at, value.var=prob, fun.aggregate = sum)
tmp_df$prob <- as.intergar(unlist(tt))
tmp_df$prob <- as.integer(unlist(tt))
year_topic <- tmp_df  %>%
group_by(created_at, topic) %>%
count(created_at, topic) %>%
dcast(topic ~ created_at, value.var= prob, fun.aggregate = sum)
year_topic <- tmp_df  %>%
group_by(created_at, topic) %>%
count(created_at, topic) %>%
dcast(.,topic ~ created_at, value.var= prob, fun.aggregate = sum)
year_topic <- tmp_df  %>%
group_by(created_at, topic) %>%
count(created_at, topic) %>%
dcast(.,topic ~ created_at, value.var= "prob", fun.aggregate = sum)
aggregate(tmp_df,list(created_at,topic),sum)
tapply(tmp_df, list(group[row(tmp_df)], col(topic)), sum)
tapply(tmp_df, list(topic[row(tmp_df)], col(topic)), sum)
x <- matrix(runif(100), ncol=5)
group <- sample(1:8, 20, T)
x
group
xsum <- rowsum(x, group)
xxsum
xxsum
xsum
View(tmp_2)
year_topic <- tmp_df  %>%
group_by(created_at, topic) %>%
count(created_at, topic) %>%
rowSums(prob, list(created_at, topic))
year_topic <- tmp_df  %>%
group_by(created_at, topic) %>%
count(created_at, topic) %>%
rowSums(prob, c(created_at, topic))
year_topic <- tmp_df  %>%
group_by(created_at, topic) %>%
count(created_at, topic) %>%
rowSums(created_at, topic)
year_topic <- tmp_df  %>%
group_by(created_at, topic) %>%
count(created_at, topic) %>%
rowSums(.,created_at, topic)
year_topic <- tmp_df  %>%
group_by(created_at, topic) %>%
count(created_at, topic) %>%
rowSums(prob,created_at, topic)
aggregate(x = tmp_df$prob,                # Specify data column
by = list(tmp_df$topic),              # Specify group indicator
FUN = sum)
aggregate(x = tmp_df$prob,                # Specify data column
by = list(tmp_df$topic, tmp_df$created_at),              # Specify group indicator
FUN = sum)
tmp_df$prob[1]
tmp_df$prob[2]
tmp_df$prob <- unlist(tt)
year_topic <- tmp_df  %>%
group_by(created_at, topic) %>%
count(created_at, topic) %>%
aggregate(x = prob,                # Specify data column
by = list(topic, created_at),              # Specify group indicator
FUN = sum)
aggregate(x = tmp_df$prob,                # Specify data column
by = list(tmp_df$topic, tmp_df$created_at),              # Specify group indicator
FUN = sum)
year_topic <- tmp_df  %>%
group_by(created_at, topic) %>%
count(created_at, topic) %>%
aggregate(prob = tmp_df$prob,                # Specify data column
by = list(tmp_df$topic, tmp_df$created_at),              # Specify group indicator
FUN = sum)
year_prob <- data.frame(aggregate(prob = tmp_df$prob,                # Specify data column
by = list(tmp_df$topic, tmp_df$created_at),              # Specify group indicator
FUN = sum))
year_prob <- as.data.frame(aggregate(prob = tmp_df$prob,                # Specify data column
by = list(tmp_df$topic, tmp_df$created_at),              # Specify group indicator
FUN = sum))
year_prob <- aggregate(prob = tmp_df$prob,                # Specify data column
by = list(tmp_df$topic, tmp_df$created_at),              # Specify group indicator
FUN = sum)
aggregate(prob = tmp_df$prob,                # Specify data column
by = list(tmp_df$topic, tmp_df$created_at),              # Specify group indicator
FUN = sum)
aggregate(prob = tmp_df$prob,                # Specify data column
by = list(tmp_df$topic, tmp_df$created_at),              # Specify group indicator
FUN = sum)
year_prob <- aggregate(x = tmp_df$prob,                # Specify data column
by = list(tmp_df$topic, tmp_df$created_at),              # Specify group indicator
FUN = sum)
year_topic$prob <- year_prob$x
View(year_topic)
year_topic <- tmp_df  %>%
group_by(created_at, topic) %>%
count(created_at, topic) %>%
mutate(prob = year_prob$x,
percent = prob/year_topic_n) %>%
select(created_at, topic, year_topic_n = n)
year_prob <- aggregate(x = tmp_df$prob,                # Specify data column
by = list(tmp_df$topic, tmp_df$created_at),              # Specify group indicator
FUN = sum)
year_topic <- tmp_df  %>%
group_by(created_at, topic) %>%
count(created_at, topic) %>%
mutate(prob = year_prob$x)
year_topic <- tmp_df  %>%
group_by(created_at, topic) %>%
count(created_at, topic) %>%
select(created_at, topic, year_topic_n = n)
year_topic$percent <- year_topic$prob / year_topic$year_topic_n *100
year_topic$prob <- year_prob$x
year_topic$percent <- year_topic$prob / year_topic$year_topic_n *100
col <- col2rgb(c("peachpuff", "royalblue", "tomato", "#B4CF68", "green", "purple", "orange","grey","red","#8DD3C7" , "pink", "blue","gold"))
#Join the two and create a percent field
year_radar_chart <- year_topic %>%
select(-year_prob, -prob) %>%
spread(created_at, percent) %>%
chartJSRadar(showToolTipLabel = TRUE,
main = "NRC video Radar", colMatrix =col)
View(year_topic)
year_radar_chart <- year_topic %>%
select(-year_topic_n, -prob) %>%
spread(created_at, percent) %>%
chartJSRadar(showToolTipLabel = TRUE,
main = "NRC video Radar", colMatrix =col)
print(year_radar_chart)
year_radar_chart <- year_topic %>%
select(-year_topic_n, -prob) %>%
spread(created_at, percent) %>%
chartJSRadar(showToolTipLabel = TRUE,
main = "Topic Radar", colMatrix =col)
print(year_radar_chart)
#create function that accepts the lda model and num word to display
topic_radarmap <- function(df ,mallet_df, k) {
doc.topics.m <- mallet.doc.topics(mallet_df, smoothed=T,
normalized=T)
tmp_df <- df[rep(seq_len(nrow(df)), each = k), ]
#tmp_df$topic <- paste("Topic", rep(1:k,  nrow(df)))
tt <- list()
for(i in 1:nrow(doc.topics.m)){
tt[[i]] <- doc.topics.m[i,]
}
tmp_df$prob <- unlist(tt)
tmp_df$created_at <- format(as.Date(tmp_df$created_at), "%Y")
year_prob <- aggregate(x = tmp_df$prob,                # Specify data column
by = list(tmp_df$topic, tmp_df$created_at),              # Specify group indicator
FUN = sum)
year_topic <- tmp_df  %>%
group_by(created_at, topic) %>%
count(created_at, topic) %>%
select(created_at, topic, year_topic_n = n)
year_topic$prob <- year_prob$x
year_topic$percent <- year_topic$prob / year_topic$year_topic_n *100
col <- col2rgb(c("peachpuff", "royalblue", "tomato", "#B4CF68", "green", "purple", "orange","grey","red","#8DD3C7" , "pink", "blue","gold"))
#Join the two and create a percent field
year_radar_chart <- year_topic %>%
select(-year_topic_n, -prob) %>%
spread(created_at, percent) %>%
chartJSRadar(showToolTipLabel = TRUE,
main = "Topic Radar", colMatrix =col)
print(year_radar_chart)
}
topic_radarmap(df_2, mallet_df_2)
df <- df_2
mallet_df <- mallet_df_2
doc.topics.m <- mallet.doc.topics(mallet_df, smoothed=T,
normalized=T)
tmp_df <- df[rep(seq_len(nrow(df)), each = k), ]
tt <- list()
for(i in 1:nrow(doc.topics.m)){
tt[[i]] <- doc.topics.m[i,]
}
tmp_df$prob <- unlist(tt)
tmp_df$created_at <- format(as.Date(tmp_df$created_at), "%Y")
year_prob <- aggregate(x = tmp_df$prob,                # Specify data column
by = list(tmp_df$topic, tmp_df$created_at),              # Specify group indicator
FUN = sum)
aggregate(x = tmp_df$prob,                # Specify data column
by = list(tmp_df$topic, tmp_df$created_at),              # Specify group indicator
FUN = sum)
View(tmp_df)
#create function that accepts the lda model and num word to display
topic_radarmap <- function(df ,mallet_df, k) {
doc.topics.m <- mallet.doc.topics(mallet_df, smoothed=T,
normalized=T)
tmp_df <- df[rep(seq_len(nrow(df)), each = k), ]
#tmp_df$topic <- paste("Topic", rep(1:k,  nrow(df)))
tt <- list()
for(i in 1:nrow(doc.topics.m)){
tt[[i]] <- doc.topics.m[i,]
}
tmp_df$prob <- unlist(tt)
tmp_df$topic <- paste("Topic", rep(1:k,  nrow(df)))
tmp_df$created_at <- format(as.Date(tmp_df$created_at), "%Y")
year_prob <- aggregate(x = tmp_df$prob,                # Specify data column
by = list(tmp_df$topic, tmp_df$created_at),              # Specify group indicator
FUN = sum)
year_topic <- tmp_df  %>%
group_by(created_at, topic) %>%
count(created_at, topic) %>%
select(created_at, topic, year_topic_n = n)
year_topic$prob <- year_prob$x
year_topic$percent <- year_topic$prob / year_topic$year_topic_n *100
col <- col2rgb(c("peachpuff", "royalblue", "tomato", "#B4CF68", "green", "purple", "orange","grey","red","#8DD3C7" , "pink", "blue","gold"))
#Join the two and create a percent field
year_radar_chart <- year_topic %>%
select(-year_topic_n, -prob) %>%
spread(created_at, percent) %>%
chartJSRadar(showToolTipLabel = TRUE,
main = "Topic Radar", colMatrix =col)
print(year_radar_chart)
}
topic_radarmap(df, mallet_df, 7)
doc_topics_tidy <- melt(doc.topics.m,
id=c("V1:20"),
variable_name = "Frequency")
head(doc_topics_tidy)
ggplot(data = doc_topics_tidy, aes(x = X1, y = value, stat = "identity")) +
geom_density(stat = "identity", position = "identity") + facet_wrap(~X2) + ylab("Frequency") + xlab("Tract") + ggtitle("Frequency of Topic Models in Tracts for the Times")
#create function that accepts the lda model and num word to display
topic_wordplot <- function(mallet_df, k, num_words = 10) {
topic.words <- mallet.topic.words(mallet_df, smoothed = T, normalized = T)
mallet_words_list <- list()
for (i in 1:as.numeric(k)) {
mallet_words_list[[i]] <- mallet.top.words(mallet_df, topic.words[i,], 100)
}
topic_mallet_list <- mallet_words_list
topic_word <- list.cbind(topic_mallet_list)
## top num_words words per topic
sort <- list()
for(i in 1:k*2-1){
sort[[i]] <- c(i,i+1)
}
sort <- do.call(rbind,sort)
tt <- list()
for(i in 1:nrow(sort)){
tt[[i]] <- cbind(topic = paste("Topic", i), topic_word[,c(sort[i,])])
}
topics_tidy <- do.call(rbind.data.frame, tt)
theme_lyrics <- function(aticks = element_blank(),
pgminor = element_blank(),
lt = element_blank(),
lp = "none")
{
theme(plot.title = element_text(hjust = 0.5), #center the title
axis.ticks = aticks, #set axis ticks to on or off
panel.grid.minor = pgminor, #turn on or off the minor grid lines
legend.title = lt, #turn on or off the legend title
legend.position = lp) #turn on or off the legend
}
word_chart <- function(data, input, title) {
data %>%
#set y = 1 to just plot one variable and use word as the label
ggplot(aes(as.factor(row), 1, label = input, fill = factor(topic) )) +
#you want the words, not the points
geom_point(color = "transparent") +
#make sure the labels don't overlap
geom_label_repel(nudge_x = .2,
direction = "y",
box.padding = 0.1,
segment.color = "transparent",
size = 3) +
facet_grid(~topic) +
theme_lyrics() +
theme(axis.text.y = element_blank(), axis.text.x = element_blank(),
#axis.title.x = element_text(size = 9),
panel.grid = element_blank(), panel.background = element_blank(),
panel.border = element_rect("lightgray", fill = NA),
strip.text.x = element_text(size = 9)) +
labs(x = NULL, y = NULL, title = title) +
#xlab(NULL) + ylab(NULL) +
#ggtitle(title) +
coord_flip()
}
top_terms <- topics_tidy %>%
group_by(topic) %>%
arrange(topic, desc(weights)) %>%
#get the top num_words PER topic
slice(seq_len(num_words)) %>%
arrange(topic, weights) %>%
#row is required for the word_chart() function
mutate(row = row_number()) %>%
ungroup()
#create a title to pass to word_chart
title <- paste("Mallet Top",num_words  ,"Terms for", k, "Topics")
#call the word_chart function you built in prep work
word_chart(top_terms, top_terms$words, title)
}
topic_wordplot(mallet_df_1, k = 7, 10)
##topic_wordsplot
library(dplyr)
library(tidytext)
library(mallet)
topic_wordplot(mallet_df_1, k = 7, 10)
library(rlist)
topic_wordplot(mallet_df_1, k = 7, 10)
library(ggrepel)
topic_wordplot(mallet_df_1, k = 7, 10)
library(ComTxt)
library(ComTxt)
library(ComTxt)
library(ComTxt)
basic_tweets <- readRDS("F:/Bea/PostDoc/RESEARCH/ComTxt/data-raw/basic_tweets.Rds")
library(dplyr) #Data manipulation (also included in the tidyverse package)
library(tidytext) #Text mining
library(tidyr) #Spread, separate, unite, text mining (also included in the tidyverse package)
library(widyr) #Use for pairwise correlation
library(textdata)
library(readxl)
twitter_sentiment <- function(df, language, undesirable_words){
#stopwords <- data.frame(word = stopwords::stopwords(language, source = "stopwords-iso"))
#stopwords$lexicon <- language
#stopwords <- as_tibble(stopwords)
#NRC_Emotion_Lexicon <- read_excel("source/NRC-Emotion-Lexicon-v0.92-In105Languages-Nov2017Translations.xlsx")
#names <- colnames(NRC_Emotion_Lexicon)
#names <-gsub(".* ","",names)
#names <-gsub("[()]","",names)
#colnames(NRC_Emotion_Lexicon) <- names
#NRC_Emotion_Lexicon <- NRC_Emotion_Lexicon %>% select(-"en...1")
custom_lexicon <- NRC_Emotion_Lexicon %>% select(language, Anger, Anticipation, Disgust,Fear, Joy, Sadness, Surprise, Trust)
colnames(custom_lexicon) <- c("word", "Anger", "Anticipation", "Disgust","Fear", "Joy", "Sadness", "Surprise", "Trust" )
custom_lexicon <- custom_lexicon[rowSums(custom_lexicon[,2:9]) >0,]
#df$text <- gsub("@\\w*", "", df$text)
#df$text <- gsub("#\\w*", "", df$text)
#Create tidy text format: Unnested, Unsummarized, -Undesirables, Stop and Short words
nrc_tidy <- df %>%
unnest_tokens(word, text) %>% #Break the lyrics into individual words
filter(!word %in% undesirable_words) %>% #Remove undesirables
filter(!nchar(word) < 3)
youtube_nrc <- nrc_tidy %>%
inner_join(custom_lexicon)
df_1 <- youtube_nrc[,1:91]
df_1<- df_1[df_1$Anger == 1,]
df_1$Anger <- "Anger"
colnames(df_1)[colnames(df_1) == "Anger"] <- "sentiment"
df_2 <- youtube_nrc[,c(1:90, 92)]
df_2<- df_2[df_2$Anticipation == 1,]
df_2$Anticipation <- "Anticipation"
colnames(df_2)[colnames(df_2) == "Anticipation"] <- "sentiment"
df_3 <- youtube_nrc[,c(1:90, 93)]
df_3<- df_3[df_3$Disgust == 1,]
df_3$Disgust <- "Disgust"
colnames(df_3)[colnames(df_3) == "Disgust"] <- "sentiment"
df_4 <- youtube_nrc[,c(1:90, 94)]
df_4<- df_4[df_4$Fear == 1,]
df_4$Fear <- "Fear"
colnames(df_4)[colnames(df_4) == "Fear"] <- "sentiment"
df_5 <- youtube_nrc[,c(1:90, 95)]
df_5<- df_5[df_5$Joy == 1,]
df_5$Joy <- "Joy"
colnames(df_5)[colnames(df_5) == "Joy"] <- "sentiment"
df_6 <- youtube_nrc[,c(1:90, 96)]
df_6<- df_6[df_6$Sadness == 1,]
df_6$Sadness <- "Sadness"
colnames(df_6)[colnames(df_6) == "Sadness"] <- "sentiment"
df_7 <- youtube_nrc[,c(1:90, 97)]
df_7<- df_7[df_7$Surprise == 1,]
df_7$Surprise <- "Surprise"
colnames(df_7)[colnames(df_7) == "Surprise"] <- "sentiment"
df_8 <- youtube_nrc[,c(1:90, 98)]
df_8<- df_8[df_8$Trust == 1,]
df_8$Trust <- "Trust"
colnames(df_8)[colnames(df_8) == "Trust"] <- "sentiment"
tmp <- rbind(df_1, df_2, df_3, df_4, df_5, df_6, df_7, df_8)
tmp <- tmp[order(tmp$created_at),]
return(tmp)
}
df_sent <- twitter_sentiment(df_pre, language = "es", undesirable_words = c("lol", "wtf"))
load("F:/Bea/PostDoc/RESEARCH/ComTxt/data/NRC_Emotion_Lexicon.rda")
df_sent <- twitter_sentiment(df_pre, language = "es", undesirable_words = c("lol", "wtf"))
df_sent <- twitter_sentiment(basic_tweets, language = "es", undesirable_words = c("lol", "wtf"))
### sentiment bar plot
sentiment_bar(df_sent, by = "%m%Y")
### sentiment wordsplot
sentiment_wordsplot(df_sent)
### sentiment circos plot
sentiment_circos(df_sent)
### sentiment radarmap
sentiment_radarmap(df_sent)
### sentiment semantic network
sentiment_semantic(df_sent, select = "Anticipation", n_nodes = 200)
df <- readRDS("F:/Bea/PostDoc/RESEARCH/ComTxt/data-raw/basic_tweets.Rds")
txt <- head(df$user_id)
txt
gsub("...", "..***", txt)
library(stringr)
str_replace(txt, "..$", "nummer")
library(stringr)
str_replace(txt, ".....$", "***")
df$user_id <- str_replace(df$user_id, ".....$", "***")
View(df)
df$screen_name <- str_replace(df$screen_name, "....$", "***")
View(df)
df$reply_to_user_id
df$reply_to_user_id <- str_replace(df$reply_to_user_id, "....$", "***")
df$retweet_user_id
df$retweet_user_id <- str_replace(df$retweet_user_id, "....$", "***")
df$quoted_screen_name
df$retweet_screen_name
df$name
df$name <- str_replace(df$name, "....$", "***")
df$name
df$name <- str_replace(df$name, ".......$", "***")
df$name
example_df <- df
save(example_df, "data/example_df.rda")
save(example_df, "data/example_df.rda")
save(example_df, "../data/example_df.rda")
save(example_df, "../data/example_df.rda")
save(example_df, "data/example_df.rda")
save(example_df, "../data/example_df.rda")
save(example_df, "/data/example_df.rda")
save(example_df, "F:/Bea/PostDoc/RESEARCH/ComTxt/data/example_df.rda")
save(example_df, "ComTxt/data/example_df.rda")
save(example_df, file="ComTxt/data/example_df.rda")
save(example_df, file="data/example_df.rda")
list_raw <- readRDS("C:/Users/LocalAdmin/OneDrive - Universitat AutÃ²noma de Barcelona/Twitter_All/data/tweets_list_raw.Rds")
View(list_raw[1])
View(list_raw[1:2])
list_tweets <- list_raw[1:2]
list_tweets[1]$data
list_tweets[1][1]
list_tweets[1][[1]]$data$author_id <-str_replace(list_tweets[1][[1]]$data$author_id, ".....$", "***")
list_tweets[1][[1]]$data$in_reply_to_user_id <-str_replace(list_tweets[1][[1]]$data$in_reply_to_user_id, ".....$", "***")
list_tweets[1][[1]]$includes$users$name <-str_replace(list_tweets[1][[1]]$includes$users$name , ".....$", "***")
list_tweets[1][[1]]$includes$users$username <-str_replace(list_tweets[1][[1]]$includes$users$username , ".....$", "***")
list_tweets[1][[1]]$includes$users$username
save(list_tweets, "data/list_tweets.rda")
save(list_tweets, file = "data/list_tweets.rda")
shiny_sentiment_semantic <-  function(df) {
require(shiny)
shinyApp(
ui = fluidPage(
sidebarLayout(
sidebarPanel(selectInput("sentiment_select", "Sentiment category:",
c("Anger" = "Anger","Anticipation" = "Anticipation","Disgust" = "Disgust","Fear" = "Fear","Joy" = "Joy","Sadness" = "Sadness","Surprise" = "Surprise","Trust" = "Trust")),
#numericInput("top_n", "top token", 40, max = 200, min = 10 )
actionButton("semantic", "Semantic network Analysis", class = "btn-primary")),
mainPanel(plotOutput("setsemanPlot"))
)
),
server = function(input, output) {
fcm_local <- reactive({
toks <- tokens(df$text, remove_punct = TRUE, remove_symbols = TRUE, verbose = TRUE)
toks <- tokens_tolower(toks)
toks <- tokens_remove(toks, padding = FALSE, min_nchar =3)
## A feature co-occurrence matrix
fcmat <-quanteda::fcm(toks, context = "window", tri = FALSE)
##selecting keywords inside fcmat
tmp <- fcmat[, as.character(input$sentiment_select)]
tmp <- convert(tmp, to = "data.frame")
colnames(tmp) <- c("nodes", "degree")
tmp <- tmp[tmp$degree > 0, ]
fcm_select(fcmat, pattern = c(tmp, as.character(input$sentiment_select)))
})
output$setsemanPlot <- renderPlot(
textplot_network(fcm_local())
)
}
)
}
